name: llama-cpp-python

on: workflow_dispatch

jobs:
  build_wheels_linux:
    name: Build wheels on ubuntu-latest
    runs-on: ubuntu-latest
    container: quay.io/pypa/manylinux_2_28_x86_64
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    defaults:
      run:
        shell: bash -el {0}

    steps:
      - uses: actions/checkout@v3
        with:
          repository: abetlen/llama-cpp-python
          submodules: true

      - name: get latest tag
        id: get-latest-tag
        run: |
          latest_tag=$(git describe --tags `git rev-list --tags --max-count=1`)
          echo "::set-output name=latest_tag::$latest_tag"

      - name: checkout latest tag
        run: git checkout ${{ steps.get-latest-tag.outputs.latest_tag }}

      - uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: ${{ matrix.python-version }}
          mamba-version: "*"
          miniforge-version: latest
          channels: conda-forge

      - name: echo conda-prefix
        run: |
          echo "LD_LIBRARY_PATH=$CONDA_PREFIX/lib" >> "$GITHUB_ENV"
          echo $CONDA_PREFIX/bin >> "$GITHUB_PATH"

      - run: mamba install -y -c "nvidia/label/cuda-12.1.1" cuda
      - run: mamba install -y build auditwheel

      - name: build wheel
        run: python -m build --wheel .
        env:
          CMAKE_ARGS: "-DLLAMA_CUBLAS=on"
          FORCE_CMAKE: "1"

      - run: auditwheel show dist/*

      - run: auditwheel repair --plat manylinux_2_28_x86_64 --exclude libllama.so --exclude libllava.so --exclude libggml_shared.so dist/*

      - uses: actions/upload-artifact@v4
        with:
          path: ./wheelhouse/*.whl
          name: llama-cpp-python-${{ matrix.python-version }}-${{ steps.get-latest-tag.outputs.latest_tag }}

  test_wheel:
    name: Test wheels
    needs: [build_wheels_linux]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest]

    steps:
      - uses: actions/setup-python@v4
        id: python
        with:
          python-version: "3.12"

      - uses: actions/download-artifact@v4
        with:
          pattern: llama-cpp-python-${{ steps.python.outputs.python-version }}-*
          path: dist

      - run: pip install -f dist llama-cpp-python

      - run: python -c "import llama_cpp"
