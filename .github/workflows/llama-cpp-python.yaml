name: llama-cpp-python

on: workflow_dispatch

jobs:
  build_wheels_linux:
    name: Build wheels on ubuntu-latest
    runs-on: ubuntu-latest
    container: quay.io/pypa/manylinux2014_x86_64
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    defaults:
      run:
        shell: bash -el {0}

    steps:
      - uses: actions/checkout@v3
        with:
          repository: abetlen/llama-cpp-python
          ref: v0.2.21
          submodules: true

      - uses: conda-incubator/setup-miniconda@v2
        with:
          python-version: ${{ matrix.python-version }}
          channels: conda-forge
          miniforge-version: latest

      - name: echo conda-prefix
        run: |
          echo "LD_LIBRARY_PATH=$CONDA_PREFIX/lib" >> "$GITHUB_ENV"
          echo $CONDA_PREFIX/bin >> "$GITHUB_PATH"

      - run: conda install -y -c "nvidia/label/cuda-12.1.1" cuda
      - run: conda install -y build auditwheel

      - name: build wheel
        run: python -m build --wheel .
        env:
          CMAKE_ARGS: "-DLLAMA_CUBLAS=on"
          FORCE_CMAKE: "1"

      - run: auditwheel show dist/*

      - run: auditwheel repair --plat manylinux_2_17_x86_64 --exclude libllama.so --exclude libllava.so --exclude libggml_shared.so dist/*

      - uses: actions/upload-artifact@v3
        with:
          path: ./wheelhouse/*.whl

  build_wheels_windows:
    name: Build wheels on windows-latest
    runs-on: windows-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11"]

    defaults:
      run:
        shell: pwsh

    steps:
      - uses: actions/checkout@v3
        with:
          repository: abetlen/llama-cpp-python
          ref: v0.2.21
          submodules: true

      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true
          python-version: ${{ matrix.python-version }}
          channels: conda-forge

      - name: echo conda-prefix
        shell: bash
        run: |
          echo "LD_LIBRARY_PATH=$CONDA_PREFIX/lib" >> "$GITHUB_ENV"
          echo $CONDA_PREFIX\\bin >> "$GITHUB_PATH"

      - run: conda install -y clblast
      - run: conda install -y build delvewheel

      - name: build wheel
        run: python -m build --wheel .
        env:
          CMAKE_ARGS: "-DLLAMA_CLBLAST=on"
          FORCE_CMAKE: "1"

      - run: delvewheel show (get-childitem dist/*.whl)

      - uses: actions/upload-artifact@v3
        with:
          path: ./dist/*.whl

  test_wheel:
    name: Test wheels
    needs: [build_wheels_linux, build_wheels_windows]
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]

    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - uses: actions/download-artifact@v3
        with:
          name: artifact
          path: dist

      - run: pip install -f dist llama-cpp-python

      - run: python -c "import llama_cpp"
