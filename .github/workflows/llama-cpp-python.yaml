name: llama-cpp-python

on: workflow_dispatch

jobs:
  build_wheels_linux:
    name: Build wheels on ubuntu-latest
    runs-on: ubuntu-latest
    container: quay.io/pypa/manylinux2014_x86_64
    strategy:
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11"]

    defaults:
      run:
        shell: bash -el {0}

    steps:
      - uses: actions/checkout@v3
        with:
          repository: abetlen/llama-cpp-python
          ref: v0.1.77
          submodules: true

      - uses: conda-incubator/setup-miniconda@v2
        with:
          python-version: ${{ matrix.python-version }}
          channels: conda-forge
          miniforge-version: latest

      - name: echo conda-prefix
        run: echo "LD_LIBRARY_PATH=$CONDA_PREFIX/lib" >> "$GITHUB_ENV"

      - run: conda install -y clblast pocl build auditwheel

      - name: build wheel
        run: python -m build --wheel .
        env:
          CMAKE_ARGS: "-DLLAMA_CLBLAST=on"
          FORCE_CMAKE: "1"

      - run: auditwheel show dist/*

      - run: auditwheel repair --plat manylinux_2_24_x86_64 dist/*

      - name: test wheel
        run: |
          pip install ./wheelhouse/*.whl
          python -c "import llama_cpp"

      - uses: actions/upload-artifact@v3
        with:
          path: ./wheelhouse/*.whl

  build_wheels_windows:
    name: Build wheels on windows-latest
    runs-on: windows-latest
    strategy:
      matrix:
        python-version: ["3.8", "3.9", "3.10", "3.11"]

    defaults:
      run:
        shell: pwsh

    steps:
      - uses: actions/checkout@v3
        with:
          repository: abetlen/llama-cpp-python
          ref: v0.1.77
          submodules: true

      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true
          python-version: ${{ matrix.python-version }}
          channels: conda-forge

      - run: conda install -y clblast delvewheel build

      - name: build wheel
        run: python -m build --wheel .
        env:
          CMAKE_ARGS: "-DLLAMA_CLBLAST=on"
          FORCE_CMAKE: "1"

      - run: delvewheel show (get-childitem dist/*.whl)

      - name: test wheel
        run: |
          pip install (get-childitem dist/*.whl)
          python -c "import llama_cpp"

      - uses: actions/upload-artifact@v3
        with:
          path: ./dist/*.whl
